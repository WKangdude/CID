{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Alan Andree Rodríguez Levario - 222791133"
      ],
      "metadata": {
        "id": "TIgQhu7P8Lkn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hands on 1"
      ],
      "metadata": {
        "id": "rnTFPdVc9Ue-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Fundamentos de la técnica"
      ],
      "metadata": {
        "id": "Eg2mdZ9p7-_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El Perceptrón es uno de los algoritmos de aprendizaje supervisado más antiguos y simples, inventado por Frank Rosenblatt en 1957. Es un clasificador binario lineal, lo que significa que toma varias entradas, las combina linealmente y, si la suma supera un cierto umbral, emite una señal (generalmente '1'), y si no, emite otra (generalmente '0' o '-1').\n",
        "\n",
        "Es el precursor de las redes neuronales artificiales, ya que se inspira en el funcionamiento de una neurona biológica: recibe señales, las pondera y se \"activa\" si el estímulo total es suficiente.\n",
        "\n",
        "La limitación principal del Perceptrón simple es que solo puede aprender y clasificar problemas que son linealmente separables. Es decir, problemas donde se puede trazar una sola línea (o un hiperplano en más dimensiones) para separar perfectamente las dos clases."
      ],
      "metadata": {
        "id": "8H3mTo9d8ZuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Modelo matemático del perceptron"
      ],
      "metadata": {
        "id": "eyWNyzBB9bIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo matemático del Perceptrón se define en dos partes: la función de entrada neta y la función de activación.\n",
        "1. Entrada Neta (z):\n",
        "  La entrada neta se calcula como la suma ponderada de las características de entrada (vector $x$) más un término de sesgo (bias, $b$).\n",
        "\n",
        "  $$z = w_1 x_1 + w_2 x_2 + \\dots + w_n x_n + b$$\n",
        "  \n",
        "  De forma vectorial, esto se expresa como:$$z = \\mathbf{w} \\cdot \\mathbf{x} + b$$Donde:$\\mathbf{w}$ es el vector de pesos.$\\mathbf{x}$ es el vector de características de entrada.$b$ es el sesgo (o bias).\n",
        "\n",
        "2. Función de Activación (predicción $\\hat{y}$): La predicción ($\\hat{y}$) se obtiene aplicando una función de activación escalón (o función escalón de Heaviside) a la entrada neta $z$.$$\\hat{y} = \\phi(z) = \\begin{cases}\n",
        "1 & \\text{si } z > \\theta \\\\\n",
        "0 & \\text{si } z \\le \\theta\n",
        "\\end{cases}$$Comúnmente, el umbral ($\\theta$) se incorpora al modelo como el sesgo (bias), moviéndolo al otro lado de la ecuación, lo que simplifica la función de activación a:$$\\hat{y} = \\phi(z) = \\begin{cases}\n",
        "1 & \\text{si } z > 0 \\\\\n",
        "0 & \\text{si } z \\le 0\n",
        "\\end{cases}$$\n",
        "\n",
        "3. Regla de Aprendizaje del Perceptrón:El entrenamiento consiste en ajustar los pesos ($w$) y el sesgo ($b$) para minimizar los errores. La regla de actualización es:$$w_i(\\text{nuevo}) = w_i(\\text{antiguo}) + \\eta (y - \\hat{y}) x_i$$$$b(\\text{nuevo}) = b(\\text{antiguo}) + \\eta (y - \\hat{y})$$Donde: $\\eta$ (eta) es la tasa de aprendizaje (un valor pequeño, ej. 0.1). $y$ es la etiqueta verdadera. $\\hat{y}$ es la predicción del modelo. Esta actualización solo ocurre cuando hay un error ($y \\neq \\hat{y}$). Si la predicción es correcta, los pesos no cambian."
      ],
      "metadata": {
        "id": "cK8yKeo19hmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Descripción de las librerías"
      ],
      "metadata": {
        "id": "0u0A_atT_rrU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para esta implementación, utilizaremos la librería Scikit-learn (sklearn), que es el estándar de la industria para el aprendizaje automático en Python.\n",
        "\n",
        "* **Librería:** sklearn.linear_model\n",
        "\n",
        "  * **Clase:** Perceptron\n",
        "  * **Descripción:** Esta es la clase que implementa el\n",
        "  algoritmo del Perceptrón. No necesitamos programar la regla de aprendizaje manualmente, ya que sklearn se encarga de ello.\n",
        "  * Parámetros clave al instanciar:\n",
        "    * eta0: Es la tasa de aprendizaje ($\\eta$).\n",
        "    * max_iter: El número máximo de épocas (pasadas por los datos de entrenamiento).\n",
        "    * random_state: Semilla para la inicialización aleatoria de pesos, lo que permite resultados reproducibles.\n",
        "\n",
        "* Librería: sklearn.datasets\n",
        "\n",
        "  * Función: load_iris\n",
        "\n",
        "  * Descripción: Esta función carga el dataset \"Iris\", que viene incluido en scikit-learn. Nos devuelve un objeto que contiene las características (datos) y las etiquetas (target).\n",
        "\n",
        "* Librería: sklearn.model_selection\n",
        "\n",
        "  * Función: train_test_split\n",
        "\n",
        "  * Descripción: A diferencia del ejemplo de la compuerta AND, el dataset Iris tiene muchos datos (150 muestras). La práctica correcta es dividir los datos en un conjunto de entrenamiento (para que el modelo aprenda) y un conjunto de prueba (para evaluarlo con datos que nunca ha visto).\n",
        "\n",
        "* Librería: sklearn.preprocessing\n",
        "\n",
        "  * Clase: StandardScaler\n",
        "\n",
        "  * Descripción: El Perceptrón funciona mejor cuando todas las características tienen una escala similar (ej. media 0 y desviación estándar 1). Esta clase nos ayuda a estandarizar nuestros datos antes de entrenar.\n",
        "\n",
        "* Librería: sklearn.metrics\n",
        "  * Función: accuracy_score\n",
        "  * Descripción: Se utiliza en la etapa de evaluación. Compara las etiquetas verdaderas ($y$) con las predicciones del modelo ($\\hat{y}$) y calcula el porcentaje de aciertos (Accuracy).\n",
        "  \n",
        "* Librería: numpy\n",
        "  * Descripción: Aunque no es parte de sklearn, numpy es fundamental. Scikit-learn espera que los datos de entrada (features y etiquetas) estén en formato de arreglos de NumPy."
      ],
      "metadata": {
        "id": "5HsmGJXE_xnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Pipeline de Implementación"
      ],
      "metadata": {
        "id": "4pUB6jAcAr_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda de importación de librerías\n",
        "import numpy as np\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris  # <-- Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "8q7qRLQkAxa9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4.1 Feature Engineering\n",
        "\n",
        "**Descripción de las variables:**\n",
        "\n",
        "* Variables de Entrada (Features): Usaremos las 4 características del dataset Iris:\n",
        "\n",
        "  1. Largo del Sépalo (cm)\n",
        "\n",
        "  2. Ancho del Sépalo (cm)\n",
        "\n",
        "  3. Largo del Pétalo (cm)\n",
        "\n",
        "  4. Ancho del Pétalo (cm)\n",
        "\n",
        "* Variable de Salida (Target): El dataset original tiene 3 clases (0: Setosa, 1: Versicolor, 2: Virginica). Modificaremos esto para crear un problema binario:\n",
        "\n",
        "  * Clase 0: Setosa\n",
        "  * Clase 1: No-Setosa (cualquier flor que sea Versicolor o Virginica)\n",
        "\n",
        "**Pasos:**\n",
        "\n",
        "  1. Cargar los datos.\n",
        "  2. Crear la etiqueta binaria y.\n",
        "  3. Dividir los datos en entrenamiento (70%) y prueba (30%).\n",
        "  4. Estandarizar (escalar) las características."
      ],
      "metadata": {
        "id": "hxovrJ_zA23S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Cargar los datos\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y_original = iris.target\n",
        "\n",
        "# 2. Crear la etiqueta binaria (Clase 0 = Setosa, Clase 1 = No-Setosa)\n",
        "# (y_original > 0) es Falso (0) para Setosa y Verdadero (1) para las otras dos\n",
        "y = (y_original > 0).astype(int)\n",
        "\n",
        "# 3. Dividir los datos en entrenamiento y prueba\n",
        "# random_state = 42 asegura que la división sea siempre la misma\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 4. Escalar los datos\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Aplicamos la misma transformación (transform) a los datos de prueba\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "867glNV-DmbK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4.2 Model Section\n",
        "\n",
        "Razones para emplear un clasificador lineal:\n",
        "\n",
        "Se ha seleccionado el Perceptrón porque el problema que hemos definido (Setosa vs. No-Setosa) es linealmente separable.\n",
        "\n",
        "La clase Setosa es morfológicamente muy distinta de las otras dos especies (Versicolor y Virginica), especialmente en las dimensiones de sus pétalos. Esto permite que un hiperplano (una \"línea\" en 4 dimensiones) separe casi perfectamente las muestras de la Clase 0 (Setosa) de las de la Clase 1 (No-Setosa).\n",
        "\n",
        "Dado que el problema es linealmente separable, el Teorema de Convergencia del Perceptrón garantiza que el algoritmo encontrará una solución."
      ],
      "metadata": {
        "id": "7ETT0cdwG79I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4.3 Model Training\n",
        "Entrenamos el modelo Perceptron usando nuestro conjunto de entrenamiento escalado (X_train_scaled e y_train)."
      ],
      "metadata": {
        "id": "F6LcUQcTHYLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Instanciar el modelo\n",
        "perceptron_model = Perceptron(eta0=0.1, max_iter=1000, random_state=42)\n",
        "\n",
        "# 2. Entrenar el modelo (Ajustar w y b)\n",
        "# Usamos los datos de entrenamiento escalados\n",
        "perceptron_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"¡Modelo entrenado exitosamente con el dataset Iris!\")\n",
        "\n",
        "# Pesos (w) y el sesgo (b) aprendidos\n",
        "print(f\"Pesos (w): {perceptron_model.coef_}\")\n",
        "print(f\"Sesgo (b): {perceptron_model.intercept_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J43HYbjYHcxd",
        "outputId": "f76ccff9-5018-486c-ea40-5a6c1caaf005"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Modelo entrenado exitosamente con el dataset Iris!\n",
            "Pesos (w): [[ 0.00689027 -0.00228438  0.07177026  0.07588896]]\n",
            "Sesgo (b): [0.1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4.4 Prediction\n",
        "\n",
        "Ahora que el modelo está entrenado, creamos una función para probar que clasifica correctamente cada patrón de entrada.\n",
        "\n",
        "La usaremos para probar el rendimiento del modelo sobre el conjunto de prueba, que el modelo nunca ha visto durante el entrenamiento."
      ],
      "metadata": {
        "id": "3_dYr5xAHmh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def probar_patrones(model, X_data, y_data):\n",
        "\n",
        "    # Obtener todas las predicciones de una vez\n",
        "    predicciones = model.predict(X_data)\n",
        "\n",
        "    # Mostramos solo los primeros 10 para no saturar la pantalla\n",
        "    for i in range(min(len(X_data), 10)):\n",
        "        patron = X_data[i]\n",
        "        etiqueta_real = y_data[i]\n",
        "        prediccion = predicciones[i]\n",
        "\n",
        "        resultado = \"CORRECTO\" if prediccion == etiqueta_real else \"INCORRECTO\"\n",
        "\n",
        "        patron_str = [f\"{p:.2f}\" for p in patron]\n",
        "\n",
        "        print(f\"Entrada: {patron_str} -> Pred: {prediccion} (Real: {etiqueta_real}) - {resultado}\")\n",
        "\n",
        "# Probamos la función con nuestro modelo y los datos de prueba escalados\n",
        "probar_patrones(perceptron_model, X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FZyF-3mkIKCc",
        "outputId": "0e70814a-ba17-4e71-8525-5d82f9b38a8a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrada: ['0.31', '-0.50', '0.48', '-0.05'] -> Pred: 1 (Real: 1) - CORRECTO\n",
            "Entrada: ['-0.17', '1.90', '-1.27', '-1.27'] -> Pred: 0 (Real: 0) - CORRECTO\n",
            "Entrada: ['2.24', '-0.98', '1.77', '1.44'] -> Pred: 1 (Real: 1) - CORRECTO\n",
            "Entrada: ['0.19', '-0.26', '0.37', '0.35'] -> Pred: 1 (Real: 1) - CORRECTO\n",
            "Entrada: ['1.15', '-0.50', '0.54', '0.22'] -> Pred: 1 (Real: 1) - CORRECTO\n",
            "Entrada: ['-0.53', '0.94', '-1.38', '-1.14'] -> Pred: 0 (Real: 0) - CORRECTO\n",
            "Entrada: ['-0.29', '-0.26', '-0.16', '0.08'] -> Pred: 1 (Real: 1) - CORRECTO\n",
            "Entrada: ['1.27', '0.22', '0.72', '1.44'] -> Pred: 1 (Real: 1) - CORRECTO\n",
            "Entrada: ['0.43', '-1.94', '0.37', '0.35'] -> Pred: 1 (Real: 1) - CORRECTO\n",
            "Entrada: ['-0.05', '-0.74', '0.02', '-0.05'] -> Pred: 1 (Real: 1) - CORRECTO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4.5 Model Evaluation\n",
        "\n",
        "Finalmente, calculamos la métrica de Accuracy (Exactitud) para evaluar el rendimiento general del modelo sobre el conjunto de datos de entrenamiento.\n",
        "\n",
        "El Accuracy se define como:\n",
        "\n",
        "$$\\text{Accuracy} = \\frac{\\text{Número de Predicciones Correctas}}{\\text{Número Total de Predicciones}}$$"
      ],
      "metadata": {
        "id": "BLeyeciZInWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Obtener predicciones para todo el conjunto de prueba\n",
        "y_pred = perceptron_model.predict(X_test_scaled)\n",
        "\n",
        "# 2. Calcular el Accuracy comparando las predicciones (y_pred) con las reales (y_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Predicciones: {y_pred}\")\n",
        "print(f\"Etiquetas reales:    {y_test}\")\n",
        "print(f\"Accuracy (Exactitud) sobre datos de prueba: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl8Ua1ffIyaJ",
        "outputId": "5aebe461-3186-43c7-8a40-a04318647b28"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicciones: [1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 0 1 1\n",
            " 0 0 0 1 1 1 0 0]\n",
            "Etiquetas reales:    [1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 0 1 1\n",
            " 0 0 0 1 1 1 0 0]\n",
            "Accuracy (Exactitud) sobre datos de prueba: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Referencias Bibliográficas\n",
        "\n",
        "Documentación oficial de Scikit-learn sobre sklearn.linear_model.Perceptron. (Consultado en https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html)\n",
        "\n",
        "Daniel. (2023, 30 octubre). Perceptrón: ¿qué es y para qué sirve? DataScientest. https://datascientest.com/es/perceptron-que-es-y-para-que-sirve"
      ],
      "metadata": {
        "id": "YKaHGHp7Jg-1"
      }
    }
  ]
}